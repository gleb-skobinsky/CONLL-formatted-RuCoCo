{"entities": [[[0, 23], [108, 131], [234, 242], [424, 432], [532, 541], [683, 688], [715, 750], [1104, 1107], [1236, 1238], [1259, 1267], [1697, 1700], [1803, 1811], [1907, 1923]], [[42, 57], [146, 161], [288, 303], [1154, 1158]], [[59, 92], [205, 217], [315, 318], [757, 782], [1367, 1379], [1878, 1891]], [[75, 92], [774, 782], [1500, 1508]], [[791, 830], [834, 841]], [[982, 993], [995, 1002]], [[1401, 1422], [1424, 1431], [1570, 1576]], [[1517, 1523], [1527, 1534]], [[1551, 1561], [1563, 1567], [1728, 1744], [1779, 1788]], [[1611, 1614]], [[1951, 1970]], [[1980, 1992]], [[1997, 2003]]], "includes": [[], [], [], [], [], [], [], [], [], [6, 8], [11, 12], [], []], "text": "Искусственный интеллект научился играть в Quake III Arena\n\nРазработчики из компании DeepMind смогли обучить искусственный интеллект (ИИ) играть в Quake III Arena не хуже настоящих геймеров.\n\nКак пишет N+1 специалистам удалось научить алгоритм адаптироваться к постоянно меняющимся картам популярной игры. Для этого они использовали обучение с подкреплением. Особенность этого вида машинного обучения, заключается в том, что алгоритм учится, не имея при этом обучающей выборки в виде пары \"входные данные – ответ\": в ходе тренировки программа получает отклик от среды (например, очки за успешное прохождение уровня или штрафные баллы за ошибки) и за счет этого улучшает эффективность своих действий.\n\nДля тренировки программы под названием For The Win (FTW) исследователи из DeepMind выбрали режим игры под названием \"Захват флага\", в котором игроки делятся на две команды, а цель состязания состоит в том, чтобы захватить флаг соперников, удержав при этом свой. Победа присуждается той команде, которая за пять минут сумеет получить и удержать флаг оппонента большее количество раз.\n\nВ процессе обучения FTW должен был вырабатывать стратегию поведения в игре, а не запомнить игровую карту. Для этого дизайн уровней постоянно менялся, а ИИ учился как человек: алгоритм наблюдал за окружением и выполнял различные действия через эмулятор игрового контроллера. При этом разработчики одновременно обучали нескольких ИИ-агентов, которые могли объединяться друг с другом.\n\nДля проверки качества обучения в DeepMind провели турнир, в котором приняли участие 40 человек. Люди и агенты в играх были случайно перемешаны: они могли попасть как в одну команду, так и в противоположные. По итогам соревнования FTW одержала больше побед, чем настоящие игроки. Кроме того, в опросе после игры, участники отметили, что алгоритм был больше расположен к сотрудничеству, чем сами люди.\n\nПо мнению разработчиков, в перспективе такая система ИИ может пройти обучение и на более сложных играх, включая StarCraft II или Dota 2.\n\nИсточник: https://www.newsru.com/hitech/05Jul2018/deepquake.html\n"}